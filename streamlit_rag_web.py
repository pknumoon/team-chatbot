import os
import streamlit as st

from openai import OpenAI
from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.vectorstores import Chroma
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_core.output_parsers import StrOutputParser
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains import create_history_aware_retriever, create_retrieval_chain
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain.prompts import ChatPromptTemplate, PromptTemplate
from langchain.schema import Document
from langchain_community.chat_message_histories.streamlit import StreamlitChatMessageHistory

__import__('pysqlite3')
import sys
sys.modules['sqlite3']=sys.modules.pop('pysqlite3')
from langchain_chroma import Chroma

# ğŸ”‘ í™˜ê²½ ì„¤ì •
os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]
client = OpenAI(api_key=os.environ["OPENAI_API_KEY"])
embedding = OpenAIEmbeddings(model="text-embedding-3-small")

# âœ… Chroma DB ì´ˆê¸°í™”
db3 = Chroma(
    persist_directory=r"/mount/src/team-chatbot/chroma_db",
    embedding_function=embedding
)

# âœ… í•œ-ì˜ êµìˆ˜ ì´ë¦„ ë§¤í•‘
professor_name_map = {
    "ë…¸ë§¹ì„": "Maengseok Noh",
    "ë¬¸í˜•ë¹ˆ": "HyungBin Moon",
    "í•˜ì§€í™˜": "Jihwan Ha",
    "ì§€ì¤€í™”": "Junhwa Chi",
}

# âœ… ë²ˆì—­ í•¨ìˆ˜
def translate_with_gpt(text, source_lang="ko", target_lang="en") -> str:
    prompt = f"Translate this from {source_lang} to {target_lang}:\n\n{text}"
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3
    )
    return response.choices[0].message.content.strip()

# âœ… ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜ í•¨ìˆ˜
def classify_question_type(question_ko: str) -> str:
    prompt = f"""
ë‹¤ìŒ ì§ˆë¬¸ì˜ ìœ í˜•ì„ ì•„ë˜ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•´ ì£¼ì„¸ìš”:
- ë…¼ë¬¸_ëª©ë¡
- ë…¼ë¬¸_ìš”ì•½
- ì—°êµ¬_íë¦„

ì§ˆë¬¸: {question_ko}
ì§ˆë¬¸ ìœ í˜•:"""
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt.strip()}],
        temperature=0
    )
    return response.choices[0].message.content.strip()

# âœ… êµìˆ˜ëª… ì¶”ì¶œ í•¨ìˆ˜
def extract_professor_name(question: str) -> str | None:
    match = re.search(r"([ê°€-í£]{2,4})\s*êµìˆ˜", question)
    return match.group(1) if match else None

# def get_first_page_summary(doc: Document) -> str:
#     title = doc.metadata.get("title", "ì œëª© ì •ë³´ ì—†ìŒ")
#     content = doc.page_content.strip().split("\n")[0]
#     return f"ğŸ“Œ ì œëª©: {title}\nğŸ“„ ìš”ì•½: {content}"

# âœ… í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜
prompt_templates = {
    "ë…¼ë¬¸_ëª©ë¡": PromptTemplate(
        input_variables=["context", "question"],
        template="""
You are provided with a collection of academic papers written by a professor. 
Based on the following user request, list the key papers along with:

1. The title of each paper (ğŸ“Œ Please keep the title in English)  
2. The publication year (if available)  
3. A few core keywords representing the main topic (in Korean)  
4. The author(s) of each paper (in Korean)

User question:
{question}

Paper content:
{context}

ğŸ“Œ Please write your response in Korean using a respectful and organized tone, **but keep the paper titles in English**.

ë…¼ë¬¸ ëª©ë¡ ìš”ì•½ (in Korean):"""
    ),
    "ë…¼ë¬¸_ìš”ì•½": PromptTemplate(
        input_variables=["context"],
        template="""
You are a research summarization assistant. Based on the following academic paper, provide a clear and concise summary including the following elements:

1. Research subject (what or who is being studied)  
2. Research method (how it was studied)  
3. Research findings (what was discovered)  
4. Suggestions or implications (recommendations or conclusions)

Paper content:
{context}

ğŸ“Œ Please write your summary in Korean, using a polite and professional tone.

ë…¼ë¬¸ ìš”ì•½ (in Korean):"""
    ),
    "ì—°êµ¬_íë¦„": PromptTemplate(
        input_variables=["context", "question"],
        template="""
You are an academic assistant. Given a collection of research papers written by a single professor, analyze how the research topics or areas of interest have evolved over time. 
Identify key shifts, trends, or patterns chronologically based on the publication content.

Context:
{context}

Question:
{question}

Now, summarize the chronological progression of the professorâ€™s research focus. 
ğŸ“Œ Please write your answer in Korean using a clear and respectful tone.

ì—°êµ¬ íë¦„ ìš”ì•½ (í•œêµ­ì–´ë¡œ):"""
    )
}

# âœ… Streamlit UI ì‹œì‘
st.set_page_config(page_title="ë…¼ë¬¸ ë¶„ì„ ì±—ë´‡", page_icon="ğŸ“„")
st.header("ğŸ“„ êµìˆ˜ë‹˜ ë…¼ë¬¸ ë¶„ì„ ì±—ë´‡")

if "messages" not in st.session_state:
    st.session_state["messages"] = [
        {"role": "assistant", "content": "ë¹…ë°ì´í„° ìœµí•© ì „ê³µ êµìˆ˜ë‹˜ë“¤ì˜ ë…¼ë¬¸ ëª©ë¡, ë…¼ë¬¸ ë‚´ìš©, ì—°êµ¬ ë™í–¥ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤ \në…¼ë¬¸ ì œëª©ì„ ë„£ì„ ì‹œ í° ë”°ì˜´í‘œë¡œ ê°ì‹¸ì£¼ì„¸ìš”"}
    ]

for msg in st.session_state["messages"]:
    st.chat_message(msg["role"]).write(msg["content"])

if prompt_message := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš” :)"):
    st.chat_message("user").write(prompt_message)
    st.session_state["messages"].append({"role": "user", "content": prompt_message})

    with st.chat_message("assistant"):
        with st.spinner("ì§ˆë¬¸ ë¶„ì„ ì¤‘..."):
            try:
                question_type = classify_question_type(prompt_message)
                target_author_ko = extract_professor_name(prompt_message)
                target_author_en = professor_name_map.get(target_author_ko) if target_author_ko else None

                if question_type in ["ë…¼ë¬¸_ëª©ë¡", "ì—°êµ¬_íë¦„"] and not target_author_en:
                    st.error("ì§ˆë¬¸ì—ì„œ ìœ íš¨í•œ êµìˆ˜ ì´ë¦„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    collection = db3._collection.get(include=["metadatas", "documents"])
                    docs = []

                    if question_type == "ë…¼ë¬¸_ìš”ì•½":
                        # ì§ˆë¬¸ì—ì„œ ë…¼ë¬¸ ì œëª© ì¶”ì¶œ
                        title_match = re.search(r'\"(.+?)\"', prompt_message)  # í°ë”°ì˜´í‘œ ì•ˆì˜ ì œëª© ì¶”ì¶œ
                        if title_match:
                            target_title = title_match.group(1).lower()
                            docs = [
                                Document(page_content=page, metadata=meta)
                                for page, meta in zip(collection["documents"], collection["metadatas"])
                                if meta.get("title", "").lower() == target_title.lower()
                            ]
                        else:
                            st.error("ë…¼ë¬¸ ì œëª©ì„ \"í°ë”°ì˜´í‘œ\"ë¡œ ê°ì‹¸ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
                    elif question_type == "ë…¼ë¬¸_ëª©ë¡":
                        docs = [
                            Document(page_content=page, metadata=meta)
                            for page, meta in zip(collection["documents"], collection["metadatas"])
                            if meta.get("professor") == target_author_en and meta.get("page") in [0, 1]
                        ]
                    elif question_type == "ì—°êµ¬_íë¦„":
                        docs = [
                            Document(page_content=page, metadata=meta)
                            for page, meta in zip(collection["documents"], collection["metadatas"])
                            if meta.get("professor") == target_author_en and meta.get("page") in [0, 1]
                        ]

                    if question_type in ["ë…¼ë¬¸_ëª©ë¡", "ì—°êµ¬_íë¦„"]:
                        context_text = "\n\n---\n\n".join(doc.page_content for doc in docs)
                    else:
                        context_text = "\n\n---\n\n".join(doc.page_content for doc in docs)

                    prompt = prompt_templates[question_type]
                    chain = prompt | ChatOpenAI(model="gpt-4o")
                    inputs = {"context": context_text}
                    if "question" in prompt.input_variables:
                        inputs["question"] = prompt_message

                    result = chain.invoke(inputs)

                    st.session_state["messages"].append({"role": "assistant", "content": result.content})
                    st.markdown(f"### ğŸ” ë¶„ì„ ê²°ê³¼: `{question_type}`")
                    st.write(result.content)

            except Exception as e:
                st.error(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
