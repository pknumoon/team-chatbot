{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d9e976",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from openai import OpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import Document\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# ğŸ”‘ í™˜ê²½ ì„¤ì •\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"OPENAI_API_KEY\"  # â† ì‹¤ì œ í‚¤ë¡œ êµì²´\n",
    "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "embedding = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ee5d3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "db3 = Chroma(\n",
    "    persist_directory=\"./chroma_db\",\n",
    "    embedding_function=embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "125131bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… í•œ-ì˜ êµìˆ˜ ì´ë¦„ ë§¤í•‘\n",
    "professor_name_map = {\n",
    "    \"ë…¸ë§¹ì„\": \"Maengseok Noh\",\n",
    "    \"ë¬¸í˜•ë¹ˆ\": \"HyungBin Moon\",\n",
    "    \"í•˜ì§€í™˜\": \"Jihwan Ha\",\n",
    "    \"ì§€ì¤€í™”\": \"Junhwa Chi\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56a87074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… ë²ˆì—­\n",
    "def translate_with_gpt(text, source_lang=\"ko\", target_lang=\"en\") -> str:\n",
    "    prompt = f\"Translate this from {source_lang} to {target_lang}:\\n\\n{text}\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.3\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1e20ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜\n",
    "def classify_question_type(question_ko: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "ë‹¤ìŒ ì§ˆë¬¸ì˜ ìœ í˜•ì„ ì•„ë˜ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•´ ì£¼ì„¸ìš”:\n",
    "- ë…¼ë¬¸_ëª©ë¡\n",
    "- ë…¼ë¬¸_ìš”ì•½\n",
    "- ì—°êµ¬_íë¦„\n",
    "\n",
    "ì§ˆë¬¸: {question_ko}\n",
    "ì§ˆë¬¸ ìœ í˜•:\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt.strip()}],\n",
    "        temperature=0\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f2a4df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The list of Professor Moon Hyung-bin's papers is\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate_with_gpt(\"ë¬¸í˜•ë¹ˆ êµìˆ˜ë‹˜ì˜ ë…¼ë¬¸ ëª©ë¡ì€\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed3fe5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… êµìˆ˜ëª… ì¶”ì¶œ\n",
    "def extract_professor_name(question: str) -> str | None:\n",
    "    match = re.search(r\"([ê°€-í£]{2,4})\\s*êµìˆ˜\", question)\n",
    "    return match.group(1) if match else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d537120",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_page_summary(doc: Document) -> str:\n",
    "    title = doc.metadata.get(\"title\", \"ì œëª© ì •ë³´ ì—†ìŒ\")\n",
    "    content = doc.page_content.strip().split(\"\\n\")[:2]  # ì²« ì¤„ë§Œ\n",
    "    return f\"ğŸ“Œ ì œëª©: {title}\\nğŸ“„ ìš”ì•½: {content}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9812b9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_doc_with_metadata(doc: Document) -> str:\n",
    "    professor = doc.metadata.get(\"professor\", \"êµìˆ˜ ì •ë³´ ì—†ìŒ\")\n",
    "    title = doc.metadata.get(\"title\", \"ì œëª© ì •ë³´ ì—†ìŒ\")\n",
    "    content = doc.page_content[:500] + \"...\" if len(doc.page_content) > 500 else doc.page_content\n",
    "    return f\"\"\"ğŸ§‘â€ğŸ« êµìˆ˜: {professor}\n",
    "ğŸ“„ ë‚´ìš© ìš”ì•½:\n",
    "{content}\n",
    "\"\"\"\n",
    "\n",
    "# âœ… í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "prompt_templates = {\n",
    "    \"ë…¼ë¬¸_ëª©ë¡\": PromptTemplate(\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "        template=\"\"\"\n",
    "You are provided with a collection of academic papers written by a professor. \n",
    "Based on the following user request, list the key papers along with:\n",
    "\n",
    "1. The title of each paper (ğŸ“Œ Please keep the title in English)  \n",
    "2. The publication year (if available)  \n",
    "3. A few core keywords representing the main topic (in Korean)  \n",
    "4. The author(s) of each paper (in Korean)\n",
    "\n",
    "User question:\n",
    "{question}\n",
    "\n",
    "Paper content:\n",
    "{context}\n",
    "\n",
    "ğŸ“Œ Please write your response in Korean using a respectful and organized tone, **but keep the paper titles in English**.\n",
    "\n",
    "ë…¼ë¬¸ ëª©ë¡ ìš”ì•½ (in Korean):\"\"\"\n",
    "    ),\n",
    "    \"ë…¼ë¬¸_ìš”ì•½\": PromptTemplate(\n",
    "        input_variables=[\"context\"],\n",
    "        template=\"\"\"\n",
    "You are a research summarization assistant. Based on the following academic paper, provide a clear and concise summary including the following elements:\n",
    "\n",
    "1. Research subject (what or who is being studied)  \n",
    "2. Research method (how it was studied)  \n",
    "3. Research findings (what was discovered)  \n",
    "4. Suggestions or implications (recommendations or conclusions)\n",
    "\n",
    "Paper content:\n",
    "{context}\n",
    "\n",
    "ğŸ“Œ Please write your summary in Korean, using a polite and professional tone.\n",
    "\n",
    "ë…¼ë¬¸ ìš”ì•½ (in Korean):\"\"\"\n",
    "    ),\n",
    "    \"ì—°êµ¬_íë¦„\": PromptTemplate(\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "        template=\"\"\"\n",
    "You are an academic assistant. Given a collection of research papers written by a single professor, analyze how the research topics or areas of interest have evolved over time. \n",
    "Identify key shifts, trends, or patterns chronologically based on the publication content.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Now, summarize the chronological progression of the professorâ€™s research focus. \n",
    "ğŸ“Œ Please write your answer in Korean using a clear and respectful tone.\n",
    "\n",
    "ì—°êµ¬ íë¦„ ìš”ì•½ (í•œêµ­ì–´ë¡œ):\"\"\"\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df673480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_question(question_ko: str):\n",
    "    # 1. ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜\n",
    "    question_type = classify_question_type(question_ko)\n",
    "\n",
    "    # 2. êµìˆ˜ ì´ë¦„ ì¶”ì¶œ\n",
    "    target_author_ko = extract_professor_name(question_ko)\n",
    "    target_author_en = professor_name_map.get(target_author_ko) if target_author_ko else None\n",
    "\n",
    "    if question_type in [\"ë…¼ë¬¸_ëª©ë¡\", \"ì—°êµ¬_íë¦„\"] and not target_author_en:\n",
    "        raise ValueError(\"ì§ˆë¬¸ì—ì„œ ìœ íš¨í•œ êµìˆ˜ ì´ë¦„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    # 3. ì§ˆë¬¸ ë²ˆì—­\n",
    "    question_en = translate_with_gpt(question_ko)\n",
    "\n",
    "    # 4. ê²€ìƒ‰ (professor ê¸°ì¤€ ìˆ˜ë™ í•„í„°ë§)\n",
    "    collection = db3._collection.get(include=[\"metadatas\", \"documents\"])\n",
    "\n",
    "    # metadatasì™€ documentsë¥¼ ë¬¶ì–´ì„œ Document ê°ì²´ë¡œ ì¬êµ¬ì„±\n",
    "    docs = [\n",
    "        Document(page_content=page, metadata=meta)\n",
    "        for page, meta in zip(collection[\"documents\"], collection[\"metadatas\"])\n",
    "        if meta.get(\"professor\") == target_author_en\n",
    "    ]\n",
    "\n",
    "    # 5. ì²« í˜ì´ì§€ ê¸°ë°˜ ìš”ì•½ìš© context êµ¬ì„±\n",
    "    context_text = \"\\n\\n---\\n\\n\".join(get_first_page_summary(doc) for doc in docs)\n",
    "\n",
    "    # 5. context êµ¬ì„±\n",
    "    if question_type == \"ë…¼ë¬¸_ëª©ë¡\":\n",
    "        context_text = \"\\n\\n---\\n\\n\".join(\n",
    "            f\"ğŸ“Œ ì œëª©: {doc.metadata.get('title', 'ì œëª© ì •ë³´ ì—†ìŒ')}\\nğŸ“„ ìš”ì•½: {doc.page_content.strip().split('\\n')[0]}\"\n",
    "            for doc in docs\n",
    "        )\n",
    "        prompt = prompt_templates[\"ë…¼ë¬¸_ëª©ë¡\"]\n",
    "\n",
    "    elif question_type == \"ì—°êµ¬_íë¦„\":\n",
    "        context_text = \"\\n\\n---\\n\\n\".join(get_first_page_summary(doc) for doc in docs)\n",
    "        prompt = prompt_templates[\"ì—°êµ¬_íë¦„\"]\n",
    "\n",
    "    else:  # ë…¼ë¬¸_ìš”ì•½\n",
    "        context_text = \"\\n\\n---\\n\\n\".join(doc.page_content for doc in docs)\n",
    "        prompt = prompt_templates[\"ë…¼ë¬¸_ìš”ì•½\"]\n",
    "\n",
    "\n",
    "\n",
    "    # 7. ì‹¤í–‰\n",
    "    chain = prompt | ChatOpenAI(model=\"gpt-4o\")\n",
    "    inputs = {\"context\": context_text}\n",
    "    if \"question\" in prompt.input_variables:\n",
    "        inputs[\"question\"] = question_ko\n",
    "\n",
    "    result = chain.invoke(inputs)\n",
    "\n",
    "    print(f\"[{question_type.upper()}]\")\n",
    "    print(result.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c9437f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ë…¼ë¬¸_ëª©ë¡]\n",
      "ë…¸ë§¹ì„ êµìˆ˜ë‹˜ì˜ ë…¼ë¬¸ì„ ë‹¤ìŒê³¼ ê°™ì´ ì •ë¦¬í•˜ì˜€ìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. **Dispersion frailty models and HGLMs**\n",
      "   - **ë°œí–‰ì—°ë„**: ì •ë³´ ì—†ìŒ\n",
      "   - **í•µì‹¬ í‚¤ì›Œë“œ**: ë¶„ì‚° ì·¨ì•½ì„± ëª¨ë¸, HGLM, í†µê³„í•™ (ë¶„ì‚° ì·¨ì•½ì„± ëª¨ë¸, HGLM, í†µê³„í•™)\n",
      "   - **ì €ì**: ë…¸ë§¹ì„, í•˜ì¸ë•, ì´ì˜ì¡°\n",
      "\n",
      "2. **Extended negative binomial hurdle models**\n",
      "   - **ë°œí–‰ì—°ë„**: ì •ë³´ ì—†ìŒ\n",
      "   - **í•µì‹¬ í‚¤ì›Œë“œ**: ë¶€ì • ì´í•­ ëª¨ë¸, ê³¼ì‚°í¬, ì œë¡œ ì¹´ìš´íŠ¸ (ë¶€ì • ì´í•­ ëª¨ë¸, ê³¼ì‚°í¬, ì œë¡œ ì¹´ìš´íŠ¸)\n",
      "   - **ì €ì**: ì •ë³´ ì—†ìŒ\n",
      "\n",
      "3. **Hierarchical likelihood approach to non-Gaussian factor analysis**\n",
      "   - **ë°œí–‰ì—°ë„**: ì •ë³´ ì—†ìŒ\n",
      "   - **í•µì‹¬ í‚¤ì›Œë“œ**: ë¹„ê°€ìš°ì‹œì•ˆ ì¸ì ë¶„ì„, ê³„ì¸µì  ìš°ë„, í†µê³„ ì‹œë®¬ë ˆì´ì…˜ (ë¹„ê°€ìš°ì‹œì•ˆ ì¸ì ë¶„ì„, ê³„ì¸µì  ìš°ë„, í†µê³„ ì‹œë®¬ë ˆì´ì…˜)\n",
      "   - **ì €ì**: ë…¸ë§¹ì„ ì™¸\n",
      "\n",
      "4. **Hierarchical likelihood methods for nonlinear and generalized linear mixed models with missing data and measurement errors in covariates**\n",
      "   - **ë°œí–‰ì—°ë„**: ì •ë³´ ì—†ìŒ\n",
      "   - **í•µì‹¬ í‚¤ì›Œë“œ**: ë¹„ì„ í˜• ëª¨ë¸, ì¼ë°˜í™” ì„ í˜• í˜¼í•© ëª¨ë¸, ëˆ„ë½ ë°ì´í„° (ë¹„ì„ í˜• ëª¨ë¸, ì¼ë°˜í™” ì„ í˜• í˜¼í•© ëª¨ë¸, ëˆ„ë½ ë°ì´í„°)\n",
      "   - **ì €ì**: ë…¸ë§¹ì„ ì™¸\n",
      "\n",
      "5. **Hierarchical-likelihood approach for nonlinear mixed-effects models**\n",
      "   - **ë°œí–‰ì—°ë„**: 2008\n",
      "   - **í•µì‹¬ í‚¤ì›Œë“œ**: ë¹„ì„ í˜• í˜¼í•©íš¨ê³¼ ëª¨ë¸, ê³„ì¸µì  ìš°ë„, ë°”ì´ì–´ìŠ¤ ê°ì†Œ (ë¹„ì„ í˜• í˜¼í•©íš¨ê³¼ ëª¨ë¸, ê³„ì¸µì  ìš°ë„, ë°”ì´ì–´ìŠ¤ ê°ì†Œ)\n",
      "   - **ì €ì**: ë…¸ë§¹ì„, ì´ì˜ì¡°\n",
      "\n",
      "6. **Multicomponent variance estimation for binary traits in family-based studies**\n",
      "   - **ë°œí–‰ì—°ë„**: 2006\n",
      "   - **í•µì‹¬ í‚¤ì›Œë“œ**: ì´ì§„ í˜•ì§ˆ, ê°€ì¡± ê¸°ë°˜ ì—°êµ¬, ë‹¤ì¤‘ ì„±ë¶„ ë¶„ì‚° ì¶”ì • (ì´ì§„ í˜•ì§ˆ, ê°€ì¡± ê¸°ë°˜ ì—°êµ¬, ë‹¤ì¤‘ ì„±ë¶„ ë¶„ì‚° ì¶”ì •)\n",
      "   - **ì €ì**: ë…¸ë§¹ì„ ì™¸\n",
      "\n",
      "7. **REML estimation for binary data in GLMMs**\n",
      "   - **ë°œí–‰ì—°ë„**: 2007\n",
      "   - **í•µì‹¬ í‚¤ì›Œë“œ**: ì´ì§„ ë°ì´í„°, ì¼ë°˜í™” ì„ í˜• í˜¼í•© ëª¨ë¸, ì œí•œ ìµœëŒ€ìš°ë„ (ì´ì§„ ë°ì´í„°, ì¼ë°˜í™” ì„ í˜• í˜¼í•© ëª¨ë¸, ì œí•œ ìµœëŒ€ìš°ë„)\n",
      "   - **ì €ì**: ë…¸ë§¹ì„, ì´ì˜ì¡°\n",
      "\n",
      "8. **Robust ascertainment-adjusted parameter estimation**\n",
      "   - **ë°œí–‰ì—°ë„**: ì •ë³´ ì—†ìŒ\n",
      "   - **í•µì‹¬ í‚¤ì›Œë“œ**: ê°•ê±´í•œ íŒŒë¼ë¯¸í„° ì¶”ì •, ê³„ì¸µì  ìš°ë„, ìœ ì „ ì—°êµ¬ (ê°•ê±´í•œ íŒŒë¼ë¯¸í„° ì¶”ì •, ê³„ì¸µì  ìš°ë„, ìœ ì „ ì—°êµ¬)\n",
      "   - **ì €ì**: ì •ë³´ ì—†ìŒ\n",
      "\n",
      "9. **Robust estimation of dropout models using hierarchical likelihood**\n",
      "   - **ë°œí–‰ì—°ë„**: 2011\n",
      "   - **í•µì‹¬ í‚¤ì›Œë“œ**: ë“œë¡­ì•„ì›ƒ ëª¨ë¸, ê°•ê±´í•œ ì¶”ì •, ê³„ì¸µì  ìš°ë„ (ë“œë¡­ì•„ì›ƒ ëª¨ë¸, ê°•ê±´í•œ ì¶”ì •, ê³„ì¸µì  ìš°ë„)\n",
      "   - **ì €ì**: ë…¸ë§¹ì„, ì´ì˜ì¡°, Michael G. Kenward\n",
      "\n",
      "ì´ ë…¼ë¬¸ë“¤ì€ ì£¼ë¡œ ê³„ì¸µì  ìš°ë„ ë°©ë²•ë¡ , ë¹„ì„ í˜• ëª¨ë¸, í†µê³„ì  ì¶”ì •ì— ëŒ€í•œ ì£¼ì œë¥¼ ë‹¤ë£¨ê³  ìˆìŠµë‹ˆë‹¤. ì¶”ê°€ì ì¸ ì„¸ë¶€ì‚¬í•­ì´ í•„ìš”í•œ ê²½ìš° íŠ¹ì • ë…¼ë¬¸ì„ ë” ê¹Šì´ ì‚´í´ë³´ì‹œê¸¸ ê¶Œì¥í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# âœ… ì‹¤í–‰ ì˜ˆì‹œ\n",
    "question_ko = \"ë…¸ë§¹ì„ êµìˆ˜ë‹˜ì˜ ë…¼ë¬¸ ì •ë¦¬í•´ì¤˜\"\n",
    "process_question(question_ko)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a50da97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ì—°êµ¬_íë¦„]\n",
      "ë…¸ë§¹ì„ êµìˆ˜ë‹˜ì˜ ì—°êµ¬ëŠ” ì£¼ë¡œ í†µê³„ ëª¨ë¸ë§ ë° ë¶„ì„ ë°©ë²•ë¡ ì— ì§‘ì¤‘ë˜ì–´ ìˆìœ¼ë©°, íŠ¹íˆ ê³„ì¸µì  ê°€ëŠ¥ë„(hierarchical likelihood)ì™€ ê´€ë ¨ëœ ì—¬ëŸ¬ ë¶„ì•¼ì— ê±¸ì³ ë‹¤ì–‘í•œ ì—°êµ¬ë¥¼ ì§„í–‰í•´ì™”ìŠµë‹ˆë‹¤. ë‹¤ìŒì€ ì—°êµ¬ ì£¼ì œì˜ ì‹œê°„ì  ë°œì „ì„ ìš”ì•½í•œ ê²ƒì…ë‹ˆë‹¤.\n",
      "\n",
      "1. **ì´ˆê¸° ì—°êµ¬ (2006ë…„ ì´ì „)**: ë…¸ë§¹ì„ êµìˆ˜ë‹˜ì€ ì´ ì‹œê¸°ì— ì£¼ë¡œ ì‚°í¬ ì·¨ì•½ì„± ëª¨ë¸ê³¼ HGLMs(Hierarchical Generalized Linear Models)ì— ëŒ€í•œ ì—°êµ¬ë¥¼ ì§„í–‰í•˜ì˜€ìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ë“¤ì€ ì£¼ë¡œ í†µê³„ ëª¨ë¸ë§ì—ì„œì˜ ì´ì§ˆì„± ê°ì§€ ë° ëª¨ë¸ë§ì— ì¤‘ì ì„ ë‘ì—ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "2. **ì¤‘ê¸° ì—°êµ¬ (2006ë…„~2012ë…„)**: ì´ ì‹œê¸°ì—ëŠ” ê³„ì¸µì  ê°€ëŠ¥ë„ ì ‘ê·¼ë²•ì„ ë‹¤ì–‘í•œ í†µê³„ ëª¨ë¸ì— ì ìš©í•˜ëŠ” ì—°êµ¬ê°€ ì£¼ë¥¼ ì´ë£¨ì—ˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ë¹„ì„ í˜• ë° ì¼ë°˜í™” ì„ í˜• í˜¼í•© ëª¨ë¸(NLMMs, GLMMs)ì—ì„œì˜ ê³„ì¸µì  ê°€ëŠ¥ë„ ë°©ë²•ë¡ ì„ ì œì•ˆí•˜ê³ , ê²°ì¸¡ ë°ì´í„°ì™€ ê³µë³€ëŸ‰ì˜ ì¸¡ì • ì˜¤ë¥˜ê°€ ìˆëŠ” ê²½ìš°ì—ë„ íš¨ìœ¨ì ì¸ ì¶”ë¡  ë°©ë²•ì„ ê°œë°œí•˜ì˜€ìŠµë‹ˆë‹¤.\n",
      "\n",
      "3. **ìµœê·¼ ì—°êµ¬ (2012ë…„ ì´í›„)**: ìµœê·¼ì—ëŠ” ê°•ê±´í•œ ì¶”ì • ë°©ë²•ì„ ì ìš©í•˜ì—¬ ë“œë¡­ì•„ì›ƒ ëª¨ë¸ê³¼ ê°™ì€ ë³µì¡í•œ ë°ì´í„° êµ¬ì¡°ë¥¼ ë‹¤ë£¨ëŠ” ì—°êµ¬ë¥¼ ì§„í–‰í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ë“¤ì€ íŠ¹íˆ ê´€ì¸¡ë˜ì§€ ì•Šì€ ë°ì´í„°ë‚˜ ê²°ì¸¡ ë°ì´í„°ê°€ ì¡´ì¬í•˜ëŠ” ê²½ìš°ì—ë„ ì •í™•í•œ ì¶”ì •ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” ë°©ë²•ë¡  ê°œë°œì— ì¤‘ì ì„ ë‘ê³  ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ê³„ì¸µì  ê°€ëŠ¥ë„ ë°©ë²•ì„ í†µí•´ ë¹„ì •ê·œ ë¶„í¬ì—ì„œë„ ì•ˆì •ì ì¸ ì¶”ì •ì„ í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì„ íƒêµ¬í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ë…¸ êµìˆ˜ë‹˜ì˜ ì—°êµ¬ëŠ” ì „ì²´ì ìœ¼ë¡œ í†µê³„ ëª¨ë¸ë§ì˜ ì •ë°€ì„±ê³¼ íš¨ìœ¨ì„±ì„ ë†’ì´ëŠ” ë° ê¸°ì—¬í•˜ê³  ìˆìœ¼ë©°, íŠ¹íˆ ë³µì¡í•œ ë°ì´í„° êµ¬ì¡°ë¥¼ ë‹¤ë£¨ëŠ” ë° ìˆì–´ ë§¤ìš° ì¤‘ìš”í•œ ì—­í• ì„ í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ì—°êµ¬ë“¤ì€ í†µê³„í•™ ë¶„ì•¼ì—ì„œì˜ ë‹¤ì–‘í•œ ì‹¤ì§ˆì  ë¬¸ì œ í•´ê²°ì— ê¸°ì—¬í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "process_question('ë…¸ë§¹ì„ êµìˆ˜ë‹˜ì˜ ì—°êµ¬ ë™í–¥')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c9941e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ë…¼ë¬¸_ìš”ì•½]\n",
      "ë…¼ë¬¸ ìš”ì•½:\n",
      "\n",
      "1. ì—°êµ¬ ì£¼ì œ: ì´ ì—°êµ¬ëŠ” ë„ì‹œ ë‚´ ë…¹ì§€ ê³µê°„ì´ ì£¼ë¯¼ë“¤ì˜ ì •ì‹  ê±´ê°•ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì¡°ì‚¬í•˜ì˜€ìŠµë‹ˆë‹¤.\n",
      "\n",
      "2. ì—°êµ¬ ë°©ë²•: ì—°êµ¬ì§„ì€ ëŒ€ê·œëª¨ ë„ì‹œ ê±°ì£¼ìë¥¼ ëŒ€ìƒìœ¼ë¡œ ì„¤ë¬¸ ì¡°ì‚¬ë¥¼ ì‹¤ì‹œí•˜ì—¬ ë…¹ì§€ ê³µê°„ ì ‘ê·¼ì„±ê³¼ ì •ì‹  ê±´ê°• ìƒíƒœ ê°„ì˜ ìƒê´€ê´€ê³„ë¥¼ ë¶„ì„í•˜ì˜€ìŠµë‹ˆë‹¤. ë˜í•œ, ìœ„ì„± ì´ë¯¸ì§€ë¥¼ í†µí•´ ë„ì‹œ ë‚´ ë…¹ì§€ ê³µê°„ì˜ ë¹„ìœ¨ì„ ì •ëŸ‰ì ìœ¼ë¡œ ì¸¡ì •í•˜ì˜€ìŠµë‹ˆë‹¤.\n",
      "\n",
      "3. ì—°êµ¬ ê²°ê³¼: ì—°êµ¬ ê²°ê³¼, ë…¹ì§€ ê³µê°„ì— ëŒ€í•œ ë†’ì€ ì ‘ê·¼ì„±ì„ ê°€ì§„ ì£¼ë¯¼ë“¤ì´ ê·¸ë ‡ì§€ ì•Šì€ ì£¼ë¯¼ë“¤ì— ë¹„í•´ ë” ê¸ì •ì ì¸ ì •ì‹  ê±´ê°• ìƒíƒœë¥¼ ë³´ê³ í•˜ì˜€ìŠµë‹ˆë‹¤. íŠ¹íˆ, ìŠ¤íŠ¸ë ˆìŠ¤ ìˆ˜ì¤€ê³¼ ìš°ìš¸ì¦ ì¦ìƒì´ ë…¹ì§€ ê³µê°„ ì ‘ê·¼ì„±ì— ë”°ë¼ ìœ ì˜ë¯¸í•˜ê²Œ ê°ì†Œí•˜ëŠ” ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤.\n",
      "\n",
      "4. ì œì•ˆ ë° í•¨ì˜: ì—°êµ¬ëŠ” ë„ì‹œ ê³„íšìì™€ ì •ì±… ì…ì•ˆìë“¤ì´ ì£¼ë¯¼ë“¤ì˜ ì •ì‹  ê±´ê°• ì¦ì§„ì„ ìœ„í•´ ë” ë§ì€ ë…¹ì§€ ê³µê°„ì„ ì¡°ì„±í•  í•„ìš”ê°€ ìˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤. ë˜í•œ, ë…¹ì§€ ê³µê°„ì˜ ì ‘ê·¼ì„±ì„ ë†’ì´ëŠ” ê²ƒì´ ì£¼ë¯¼ë“¤ì˜ ì „ë°˜ì ì¸ ì‚¶ì˜ ì§ˆ í–¥ìƒì— ê¸°ì—¬í•  ìˆ˜ ìˆë‹¤ëŠ” ê²°ë¡ ì„ ë‚´ë ¸ìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "process_question('Hierarchical likelihood methods for nonlinear and generalized linear mixed models with missing data and measurement errors in covariatesë…¼ë¬¸ ì •ë¦¬í•´ì¤˜')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
