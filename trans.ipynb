{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d9e976",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from openai import OpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import Document\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "client = OpenAI(api_key=\"OPENAI_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"OPENAI_API_KEY\"\n",
    "\n",
    "openai_embedding=OpenAIEmbeddings(model = 'text-embedding-3-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ee5d3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "db3 = Chroma(\n",
    "    persist_directory=\"./chroma_db\",\n",
    "    embedding_function=OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1e20ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_with_gpt(text, source_lang=\"ko\", target_lang=\"en\"):\n",
    "    prompt = f\"Translate this from {source_lang} to {target_lang}:\\n\\n{text}\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.3\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f2a4df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The list of Professor Mun Hyung-bin's papers is\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate_with_gpt(\"ë¬¸í˜•ë¹ˆ êµìˆ˜ë‹˜ì˜ ë…¼ë¬¸ ëª©ë¡ì€\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9812b9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_question_type(question_ko):\n",
    "    prompt = f\"\"\"\n",
    "ë‹¤ìŒ ì§ˆë¬¸ì˜ ìœ í˜•ì„ ì•„ë˜ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•´ ì£¼ì„¸ìš”:\n",
    "- ë…¼ë¬¸_ëª©ë¡\n",
    "- ë…¼ë¬¸_ìš”ì•½\n",
    "- ì—°êµ¬_íë¦„\n",
    "\n",
    "ì§ˆë¬¸: {question_ko}\n",
    "ì§ˆë¬¸ ìœ í˜•:\"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt.strip()}],\n",
    "        temperature=0\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df673480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ë…¼ë¬¸_ëª©ë¡]\n",
      "ë…¸ë§¹ì„ êµìˆ˜ë‹˜ì˜ ë…¼ë¬¸ ëª©ë¡ì„ ì •ë¦¬í•˜ì—¬ ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ì•„ë˜ëŠ” ì£¼ìš” ë…¼ë¬¸ë“¤ì˜ ì •ë³´ì…ë‹ˆë‹¤.\n",
      "\n",
      "1. ë…¼ë¬¸ ì œëª©: **\"ìŠ¤ë§ˆíŠ¸ íŒ©í† ë¦¬ì—ì„œì˜ ì¸ê³µì§€ëŠ¥ í™œìš©ë°©ì•ˆ\"**  \n",
      "   ì¶œíŒ ì—°ë„: 2020  \n",
      "   í•µì‹¬ í‚¤ì›Œë“œ: ìŠ¤ë§ˆíŠ¸ íŒ©í† ë¦¬, ì¸ê³µì§€ëŠ¥, ìë™í™”  \n",
      "   ì €ì: ë…¸ë§¹ì„\n",
      "\n",
      "2. ë…¼ë¬¸ ì œëª©: **\"ë°ì´í„° ë§ˆì´ë‹ì„ í†µí•œ ì†Œë¹„ì í–‰ë™ ë¶„ì„\"**  \n",
      "   ì¶œíŒ ì—°ë„: 2018  \n",
      "   í•µì‹¬ í‚¤ì›Œë“œ: ë°ì´í„° ë§ˆì´ë‹, ì†Œë¹„ì í–‰ë™, ë¹…ë°ì´í„°  \n",
      "   ì €ì: ë…¸ë§¹ì„\n",
      "\n",
      "3. ë…¼ë¬¸ ì œëª©: **\"ê¸°ê³„ í•™ìŠµì„ ì´ìš©í•œ ê¸ˆìœµ ì‹œì¥ ì˜ˆì¸¡\"**  \n",
      "   ì¶œíŒ ì—°ë„: 2019  \n",
      "   í•µì‹¬ í‚¤ì›Œë“œ: ê¸°ê³„ í•™ìŠµ, ê¸ˆìœµ ì‹œì¥, ì˜ˆì¸¡ ëª¨ë¸  \n",
      "   ì €ì: ë…¸ë§¹ì„, ê¹€ë¯¼ìˆ˜\n",
      "\n",
      "4. ë…¼ë¬¸ ì œëª©: **\"ë¸”ë¡ì²´ì¸ ê¸°ìˆ ì˜ ë³´ì•ˆì„± ë¶„ì„\"**  \n",
      "   ì¶œíŒ ì—°ë„: 2021  \n",
      "   í•µì‹¬ í‚¤ì›Œë“œ: ë¸”ë¡ì²´ì¸, ë³´ì•ˆ, ì•”í˜¸í™”  \n",
      "   ì €ì: ë…¸ë§¹ì„, ì´ì§€ì€\n",
      "\n",
      "5. ë…¼ë¬¸ ì œëª©: **\"ììœ¨ì£¼í–‰ì°¨ì˜ ì„¼ì„œ ìœµí•© ê¸°ìˆ \"**  \n",
      "   ì¶œíŒ ì—°ë„: 2022  \n",
      "   í•µì‹¬ í‚¤ì›Œë“œ: ììœ¨ì£¼í–‰ì°¨, ì„¼ì„œ ìœµí•©, ê¸°ìˆ  í˜ì‹   \n",
      "   ì €ì: ë…¸ë§¹ì„\n",
      "\n",
      "ìœ„ì˜ ëª©ë¡ì€ ë…¸ë§¹ì„ êµìˆ˜ë‹˜ì˜ ì£¼ìš” ì—°êµ¬ ë…¼ë¬¸ì„ ì„ ë³„í•˜ì—¬ ì •ë¦¬í•œ ê²ƒì…ë‹ˆë‹¤. ì¶”ê°€ì ì¸ ì •ë³´ê°€ í•„ìš”í•˜ì‹œê±°ë‚˜ ë‹¤ë¥¸ ë¬¸ì˜ ì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”.\n"
     ]
    }
   ],
   "source": [
    "# ğŸ” êµìˆ˜ ì´ë¦„ ìë™ ì¶”ì¶œ í•¨ìˆ˜\n",
    "def extract_professor_name(question: str) -> str | None:\n",
    "    match = re.search(r\"([ê°€-í£]{2,4})\\s*êµìˆ˜\", question)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "# ğŸ“ í•œê¸€ ì§ˆë¬¸ ì…ë ¥\n",
    "question_ko = \"ë…¸ë§¹ì„ êµìˆ˜ë‹˜ì˜ ë…¼ë¬¸ ì •ë¦¬í•´ì¤˜\"\n",
    "\n",
    "# 1. ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜\n",
    "question_type = classify_question_type(question_ko).strip()\n",
    "\n",
    "# 2. êµìˆ˜ ì´ë¦„ ì¶”ì¶œ (í•„ìš”í•  ë•Œë§Œ)\n",
    "target_author = extract_professor_name(question_ko)\n",
    "if question_type in [\"ë…¼ë¬¸_ëª©ë¡\", \"ì—°êµ¬_íë¦„\"] and not target_author:\n",
    "    raise ValueError(\"ì§ˆë¬¸ì—ì„œ êµìˆ˜ ì´ë¦„ì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# 3. ì˜ì–´ ë²ˆì—­\n",
    "question_en = translate_with_gpt(question_ko)\n",
    "\n",
    "# 4. Chroma DB ê²€ìƒ‰\n",
    "docs = db3.similarity_search(question_en, k=30)\n",
    "\n",
    "# 5. êµìˆ˜ ì´ë¦„ í•„í„°ë§ (í•„ìš”í•  ê²½ìš°ë§Œ ì ìš©)\n",
    "if question_type in [\"ë…¼ë¬¸_ëª©ë¡\", \"ì—°êµ¬_íë¦„\"]:\n",
    "    docs = [\n",
    "        doc for doc in docs\n",
    "        if target_author in doc.page_content or target_author in doc.metadata.get(\"author\", \"\")\n",
    "    ]\n",
    "\n",
    "# 6. context êµ¬ì„±\n",
    "context_text = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# 7. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜\n",
    "prompt_templates = {\n",
    "    \"ë…¼ë¬¸_ëª©ë¡\": PromptTemplate(\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "        template=\"\"\"\n",
    "You are provided with a collection of academic papers written by a professor. \n",
    "Based on the following user request, list the key papers along with:\n",
    "\n",
    "1. The title of each paper  \n",
    "2. The publication year (if available)  \n",
    "3. A few core keywords representing the main topic  \n",
    "4. The author(s) of each paper\n",
    "\n",
    "User question:\n",
    "{question}\n",
    "\n",
    "Paper content:\n",
    "{context}\n",
    "\n",
    "ğŸ“Œ Please write your response in Korean using a respectful and organized tone.\n",
    "\n",
    "ë…¼ë¬¸ ëª©ë¡ ìš”ì•½ (in Korean):\"\"\"\n",
    "    ),\n",
    "    \"ë…¼ë¬¸_ìš”ì•½\": PromptTemplate(\n",
    "        input_variables=[\"context\"],\n",
    "        template=\"\"\"\n",
    "You are a research summarization assistant. Based on the following academic paper, provide a clear and concise summary including the following elements:\n",
    "\n",
    "1. Research subject (what or who is being studied)  \n",
    "2. Research method (how it was studied)  \n",
    "3. Research findings (what was discovered)  \n",
    "4. Suggestions or implications (recommendations or conclusions)\n",
    "\n",
    "Paper content:\n",
    "{context}\n",
    "\n",
    "ğŸ“Œ Please write your summary in Korean, using a polite and professional tone.\n",
    "\n",
    "ë…¼ë¬¸ ìš”ì•½ (in Korean):\"\"\"\n",
    "    ),\n",
    "    \"ì—°êµ¬_íë¦„\": PromptTemplate(\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "        template=\"\"\"\n",
    "You are an academic assistant. Given a collection of research papers written by a single professor, analyze how the research topics or areas of interest have evolved over time. \n",
    "Identify key shifts, trends, or patterns chronologically based on the publication content.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Now, summarize the chronological progression of the professorâ€™s research focus. \n",
    "ğŸ“Œ Please write your answer in Korean using a clear and respectful tone.\n",
    "\n",
    "ì—°êµ¬ íë¦„ ìš”ì•½ (í•œêµ­ì–´ë¡œ):\"\"\"\n",
    "    )\n",
    "}\n",
    "\n",
    "# 8. í”„ë¡¬í”„íŠ¸ ì„ íƒ + LLM ì²´ì¸ êµ¬ì„±\n",
    "prompt = prompt_templates.get(question_type, prompt_templates[\"ë…¼ë¬¸_ìš”ì•½\"])\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "chain = prompt | llm\n",
    "\n",
    "# 9. ì‹¤í–‰\n",
    "inputs = {\"context\": context_text}\n",
    "if \"question\" in prompt.input_variables:\n",
    "    inputs[\"question\"] = question_ko\n",
    "\n",
    "result = chain.invoke(inputs)\n",
    "\n",
    "# 10. ì¶œë ¥\n",
    "print(f\"[{question_type.upper()}]\")\n",
    "print(result.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a9afb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ë…¼ë¬¸_ëª©ë¡]\n",
      "ë…¸ë§¹ì„ êµìˆ˜ë‹˜ì˜ ë…¼ë¬¸ ëª©ë¡ ìš”ì•½:\n",
      "\n",
      "1. **ë…¼ë¬¸ ì œëª©:** Hierarchical likelihood approach to non-Gaussian factor analysis  \n",
      "   - **ì¶œíŒ ì—°ë„:** 2019  \n",
      "   - **í•µì‹¬ í‚¤ì›Œë“œ:** ê³„ì¸µì  ê°€ëŠ¥ë„, ë¹„ì •ê·œ ë¶„í¬, ìš”ì¸ ë¶„ì„  \n",
      "   - **ì €ì:** ë…¸ë§¹ì„, ì´ì˜ì¡°, Han Oud, Toni Toharudin  \n",
      "\n",
      "2. **ë…¼ë¬¸ ì œëª©:** Managing spent nuclear fuel in South Korea: Heterogeneous public attitudes toward different management strategies at individual- and segment levels  \n",
      "   - **ì¶œíŒ ì—°ë„:** 2020  \n",
      "   - **í•µì‹¬ í‚¤ì›Œë“œ:** ì‚¬ìš©í›„í•µì—°ë£Œ, ê³µê³µ íƒœë„, ê´€ë¦¬ ì „ëµ  \n",
      "   - **ì €ì:** ë¬¸í˜•ë¹ˆ, ìš°ì¢…ë£°  \n",
      "\n",
      "3. **ë…¼ë¬¸ ì œëª©:** Robust estimation of dropout models using hierarchical likelihood  \n",
      "   - **ì¶œíŒ ì—°ë„:** 2010  \n",
      "   - **í•µì‹¬ í‚¤ì›Œë“œ:** ë“œë¡­ì•„ì›ƒ ëª¨ë¸, ê³„ì¸µì  ê°€ëŠ¥ë„, ê°•ê±´ ì¶”ì •  \n",
      "   - **ì €ì:** ë…¸ë§¹ì„, ì´ì˜ì¡°, Michael G. Kenward  \n",
      "\n",
      "4. **ë…¼ë¬¸ ì œëª©:** Robust Ascertainment-Adjusted Parameter Estimation  \n",
      "   - **ì¶œíŒ ì—°ë„:** ì •ë³´ ì œê³µ ì•ˆ ë¨  \n",
      "   - **í•µì‹¬ í‚¤ì›Œë“œ:** ìœ ì „ ì—°êµ¬, ê°•ê±´ ì¶”ì •, íŒŒë¼ë¯¸í„° ì¶”ì •  \n",
      "   - **ì €ì:** ë…¸ë§¹ì„, ì´ì˜ì¡°, Yudi Pawitan  \n",
      "\n",
      "5. **ë…¼ë¬¸ ì œëª©:** Attitudes in Korea toward Introducing Smart Policing Technologies: Differences between the General Public and Police Officers  \n",
      "   - **ì¶œíŒ ì—°ë„:** 2017  \n",
      "   - **í•µì‹¬ í‚¤ì›Œë“œ:** ìŠ¤ë§ˆíŠ¸ í´ë¦¬ì‹±, ê³µê³µ íƒœë„, ê²½ì°°ê´€ íƒœë„  \n",
      "   - **ì €ì:** ë¬¸í˜•ë¹ˆ, ìµœí˜„í™, ì´ì¢…ìˆ˜, ì´ê¸°ìˆ˜  \n",
      "\n",
      "ì´ ì™¸ì—ë„ ë‹¤ì–‘í•œ ì—°êµ¬ ì£¼ì œë¥¼ ë‹¤ë£¬ ë…¼ë¬¸ë“¤ì´ ìˆìœ¼ë©°, ë…¸ë§¹ì„ êµìˆ˜ë‹˜ì˜ ì—°êµ¬ëŠ” ì£¼ë¡œ í†µê³„ ëª¨ë¸ë§, ë°ì´í„° ë¶„ì„, ì •ì±… í‰ê°€ ë“±ì— ì§‘ì¤‘ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# 1. í•œê¸€ ì§ˆë¬¸ ì…ë ¥\n",
    "question_ko = \"ë…¸ë§¹ì„ êµìˆ˜ë‹˜ì˜ ë…¼ë¬¸ ëª©ë¡\"\n",
    "\n",
    "# 2. ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜\n",
    "question_type = classify_question_type(question_ko).strip()\n",
    "\n",
    "# 3. ì§ˆë¬¸ ì˜ì–´ë¡œ ë²ˆì—­ (Chroma DB ê²€ìƒ‰ìš©)\n",
    "question_en = translate_with_gpt(question_ko)\n",
    "\n",
    "# 4. Chroma DB ê²€ìƒ‰\n",
    "docs = db3.similarity_search(question_en, k=60)\n",
    "filtered_docs = [doc for doc in docs if \"ë¬¸í˜•ë¹ˆ\" in doc.page_content or \"ë¬¸í˜•ë¹ˆ\" in doc.metadata.get(\"author\", \"\")]\n",
    "context_text = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "# 5. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜\n",
    "prompt_templates = {\n",
    "    \"ë…¼ë¬¸_ëª©ë¡\": PromptTemplate(\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "        template=\"\"\"\n",
    "You are provided with a collection of academic papers written by a professor. \n",
    "Based on the following user request, list the key papers along with:\n",
    "\n",
    "1. The title of each paper  \n",
    "2. The publication year (if available)  \n",
    "3. A few core keywords representing the main topic  \n",
    "4. The author(s) of each paper\n",
    "\n",
    "User question:\n",
    "{question}\n",
    "\n",
    "Paper content:\n",
    "{context}\n",
    "\n",
    "ğŸ“Œ Please write your response in Korean using a respectful and organized tone.\n",
    "\n",
    "ë…¼ë¬¸ ëª©ë¡ ìš”ì•½ (in Korean):\"\"\"\n",
    "    ),\n",
    "    \"ë…¼ë¬¸_ìš”ì•½\": PromptTemplate(\n",
    "        input_variables=[\"context\"],\n",
    "        template=\"\"\"\n",
    "You are a research summarization assistant. Based on the following academic paper, provide a clear and concise summary including the following elements:\n",
    "\n",
    "1. Research subject (what or who is being studied)  \n",
    "2. Research method (how it was studied)  \n",
    "3. Research findings (what was discovered)  \n",
    "4. Suggestions or implications (recommendations or conclusions)\n",
    "\n",
    "Paper content:\n",
    "{context}\n",
    "\n",
    "ğŸ“Œ Please write your summary in Korean, using a polite and professional tone.\n",
    "\n",
    "ë…¼ë¬¸ ìš”ì•½ (in Korean):\"\"\"\n",
    "    ),\n",
    "    \"ì—°êµ¬_íë¦„\": PromptTemplate(\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "        template=\"\"\"\n",
    "You are an academic assistant. Given a collection of research papers written by a single professor, analyze how the research topics or areas of interest have evolved over time. \n",
    "Identify key shifts, trends, or patterns chronologically based on the publication content.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Now, summarize the chronological progression of the professorâ€™s research focus. \n",
    "ğŸ“Œ Please write your answer in Korean using a clear and respectful tone.\n",
    "\n",
    "ì—°êµ¬ íë¦„ ìš”ì•½ (í•œêµ­ì–´ë¡œ):\"\"\"\n",
    "    )\n",
    "}\n",
    "\n",
    "# 6. í”„ë¡¬í”„íŠ¸ ì„ íƒ + LLM êµ¬ì„±\n",
    "prompt = prompt_templates.get(question_type, prompt_templates[\"ë…¼ë¬¸_ìš”ì•½\"])\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "chain = prompt | llm  # ìµœì‹  LangChain ë°©ì‹\n",
    "\n",
    "# 7. ì‹¤í–‰\n",
    "inputs = {\"context\": context_text}\n",
    "if \"question\" in prompt.input_variables:\n",
    "    inputs[\"question\"] = question_ko\n",
    "\n",
    "result = chain.invoke(inputs)\n",
    "\n",
    "# 8. ê²°ê³¼ ì¶œë ¥\n",
    "print(f\"[{question_type.upper()}]\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc070ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ë…¼ë¬¸_ìš”ì•½]\n",
      "**ì—°êµ¬ëŒ€ìƒ**: ì´ ë…¼ë¬¸ì€ í•œêµ­ì˜ ì‚¬ìš©í›„ í•µì—°ë£Œ ê´€ë¦¬ì— ëŒ€í•œ ëŒ€ì¤‘ì˜ íƒœë„ì™€ ì„ í˜¸ë„ë¥¼ ì¡°ì‚¬í–ˆìŠµë‹ˆë‹¤. ì—°êµ¬ëŠ” ê°œë³„ ìˆ˜ì¤€ê³¼ ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜ì¤€ì—ì„œ ëŒ€ì¤‘ì˜ ì„ í˜¸ë¥¼ ë¶„ì„í–ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "**ì—°êµ¬ë°©ë²•**: ì—°êµ¬ëŠ” ì„ íƒ ì‹¤í—˜ê³¼ ê³„ì¸µì  ë² ì´ì§€ì•ˆ ì •ìƒ í˜¼í•© ì´ì‚° ì„ íƒ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ìˆ˜í–‰ë˜ì—ˆìŠµë‹ˆë‹¤. ë˜í•œ, ë‹¤ì–‘í•œ ê´€ë¦¬ ì „ëµì— ëŒ€í•œ ëŒ€ì¤‘ì˜ ìˆ˜ìš©ë„ë¥¼ ì‚¬ì „ ì‹œë®¬ë ˆì´ì…˜ì„ í†µí•´ ë¹„êµí–ˆìŠµë‹ˆë‹¤. ëŒ€ì¤‘ì€ ë‘ ê°œì˜ ì„¸ê·¸ë¨¼íŠ¸ë¡œ ë¶„ë¥˜ë˜ì—ˆìŠµë‹ˆë‹¤: ì„¸ê·¸ë¨¼íŠ¸ 1(31.62%)ê³¼ ì„¸ê·¸ë¨¼íŠ¸ 2(62.38%).\n",
      "\n",
      "**ì—°êµ¬ê²°ê³¼**: ì„¸ê·¸ë¨¼íŠ¸ 1ì€ ì „ê¸° ë¹„ìš© ì¦ê°€ì— ë” ë¯¼ê°í•˜ë©° ë¯¼ì£¼ì  ì ˆì°¨ë¥¼ ì„ í˜¸í–ˆìŠµë‹ˆë‹¤. ë°˜ë©´ ì„¸ê·¸ë¨¼íŠ¸ 2ëŠ” ì‚¬ìš©í›„ í•µì—°ë£Œ ì¬ì²˜ë¦¬ë¥¼ ì–´ëŠ ì •ë„ ìˆ˜ìš©í•  ìˆ˜ ìˆì—ˆê³ , ì˜êµ¬ ì €ì¥ì†Œì— ëŒ€í•œ ìˆ˜ìš©ë„ê°€ ë†’ì•˜ìŠµë‹ˆë‹¤. ì „ì²´ì ìœ¼ë¡œ ì˜êµ¬ ì €ì¥ì†Œ ê±´ì„¤ ë° ìš´ì˜ì— ëŒ€í•œ ëŒ€ì¤‘ì˜ ìˆ˜ìš©ë„ê°€ ê°€ì¥ ë†’ì•˜ìŠµë‹ˆë‹¤(55.00%).\n",
      "\n",
      "**ì œì–¸**: í•œêµ­ ì •ë¶€ëŠ” ì˜êµ¬ ì €ì¥ì†Œ ê±´ì„¤ ì‹œ ëŒ€ì¤‘ì˜ ì§€ì§€ë¥¼ ë°›ì„ ê°€ëŠ¥ì„±ì´ ë†’ìœ¼ë©°, ì„¸ê·¸ë¨¼íŠ¸ 1ì˜ ëŒ€ì¤‘ì„ ì„¸ê·¸ë¨¼íŠ¸ 2ë¡œ ì´ë™ì‹œí‚¤ê¸° ìœ„í•œ ê³µê³µ ì •ë³´ ìº í˜ì¸ì„ í†µí•´ ì‚¬íšŒì  í•©ì˜ë¥¼ ë„ì¶œí•  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ì •ì±… ê²°ì • ê³¼ì •ì—ì„œ ëŒ€ì¤‘ ì°¸ì—¬ë¥¼ ê°•í™”í•˜ì—¬ ëŒ€ì¤‘ì˜ ìˆ˜ìš©ë„ë¥¼ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# 1. í•œê¸€ ì§ˆë¬¸ ì…ë ¥\n",
    "question_ko = \"Managing spent nuclear fuel in South Korea: Heterogeneous public attitudes toward different management strategies at individual- and segment levelsë…¼ë¬¸ì„ ìš”ì•½í•´ì¤˜\"\n",
    "\n",
    "# 2. ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜\n",
    "question_type = classify_question_type(question_ko).strip()\n",
    "\n",
    "# 3. ì§ˆë¬¸ ì˜ì–´ë¡œ ë²ˆì—­ (Chroma DB ê²€ìƒ‰ìš©)\n",
    "question_en = translate_with_gpt(question_ko)\n",
    "\n",
    "# 4. Chroma DB ê²€ìƒ‰\n",
    "docs = db3.similarity_search(question_en, k=30)\n",
    "context_text = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "# 5. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜\n",
    "prompt_templates = {\n",
    "    \"ë…¼ë¬¸_ëª©ë¡\": PromptTemplate(\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "        template=\"\"\"\n",
    "You are provided with a collection of academic papers written by a professor. \n",
    "Based on the following user request, list the key papers along with:\n",
    "\n",
    "1. The title of each paper  \n",
    "2. The publication year (if available)  \n",
    "3. A few core keywords representing the main topic\n",
    "\n",
    "User question:\n",
    "{question}\n",
    "\n",
    "Paper content:\n",
    "{context}\n",
    "\n",
    "ğŸ“Œ Please write your response in Korean using a respectful and organized tone.\n",
    "\n",
    "ë…¼ë¬¸ ëª©ë¡ ìš”ì•½ (in Korean):\"\"\"\n",
    "    ),\n",
    "    \"ë…¼ë¬¸_ìš”ì•½\": PromptTemplate(\n",
    "        input_variables=[\"context\"],\n",
    "        template=\"\"\"\n",
    "You are a research summarization assistant. Based on the following academic paper, provide a clear and concise summary including the following elements:\n",
    "\n",
    "1. Research subject (what or who is being studied)  \n",
    "2. Research method (how it was studied)  \n",
    "3. Research findings (what was discovered)  \n",
    "4. Suggestions or implications (recommendations or conclusions)\n",
    "\n",
    "Paper content:\n",
    "{context}\n",
    "\n",
    "ğŸ“Œ Please write your summary in Korean, using a polite and professional tone.\n",
    "\n",
    "ë…¼ë¬¸ ìš”ì•½ (in Korean):\"\"\"\n",
    "    ),\n",
    "    \"ì—°êµ¬_íë¦„\": PromptTemplate(\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "        template=\"\"\"\n",
    "You are an academic assistant. Given a collection of research papers written by a single professor, analyze how the research topics or areas of interest have evolved over time. \n",
    "Identify key shifts, trends, or patterns chronologically based on the publication content.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Now, summarize the chronological progression of the professorâ€™s research focus. \n",
    "ğŸ“Œ Please write your answer in Korean using a clear and respectful tone.\n",
    "\n",
    "ì—°êµ¬ íë¦„ ìš”ì•½ (í•œêµ­ì–´ë¡œ):\"\"\"\n",
    "    )\n",
    "}\n",
    "\n",
    "# 6. í”„ë¡¬í”„íŠ¸ ì„ íƒ + LLM êµ¬ì„±\n",
    "prompt = prompt_templates.get(question_type, prompt_templates[\"ë…¼ë¬¸_ìš”ì•½\"])\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "chain = prompt | llm  # ìµœì‹  LangChain ë°©ì‹\n",
    "\n",
    "# 7. ì‹¤í–‰\n",
    "inputs = {\"context\": context_text}\n",
    "if \"question\" in prompt.input_variables:\n",
    "    inputs[\"question\"] = question_ko\n",
    "\n",
    "result = chain.invoke(inputs)\n",
    "\n",
    "# 8. ê²°ê³¼ ì¶œë ¥\n",
    "print(f\"[{question_type.upper()}]\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b168136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ì—°êµ¬_íë¦„]\n",
      "ë…¸ë§¹ì„ êµìˆ˜ë‹˜ì˜ ì—°êµ¬ëŠ” ë‹¤ì–‘í•œ ë¶„ì•¼ì— ê±¸ì³ ë°œì „í•´ì™”ìŠµë‹ˆë‹¤. ì´ˆê¸°ì—ëŠ” ì£¼ë¡œ í†µê³„ ëª¨ë¸ë§ê³¼ ê´€ë ¨ëœ ì—°êµ¬ë¥¼ ì§„í–‰í•˜ì˜€ê³ , íŠ¹íˆ ë¹„ì •ê·œ ë¶„í¬ë¥¼ ë‹¤ë£¨ëŠ” ê³„ì¸µì  ì¼ë°˜í™” ì„ í˜• ëª¨ë¸(HGLM) ë° ë¶„ì‚° í”„ë ˆì¼í‹° ëª¨ë¸ì— ëŒ€í•œ ì—°êµ¬ë¥¼ í†µí•´ ì˜ë£Œ ë°ì´í„° ë¶„ì„ì—ì„œì˜ ì´ì§ˆì„±ì„ ì„¤ëª…í•˜ëŠ” ë° ê¸°ì—¬í–ˆìŠµë‹ˆë‹¤. \n",
      "\n",
      "ì´í›„, ê·¸ì˜ ì—°êµ¬ëŠ” ìƒë¬¼ì •ë³´í•™ê³¼ ì˜ë£Œ/ê±´ê°• ì •ë³´í•™ìœ¼ë¡œ í™•ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ê¸°ê³„ í•™ìŠµê³¼ ë°ì´í„° ë§ˆì´ë‹ ê¸°ë²•ì„ í™œìš©í•˜ì—¬ ì§ˆë³‘ê³¼ miRNAì˜ ì—°ê´€ì„±ì„ ì˜ˆì¸¡í•˜ëŠ” ì—°êµ¬ë¥¼ ìˆ˜í–‰í•¨ìœ¼ë¡œì¨, ìƒë¬¼ì˜í•™ì  ë¬¸ì œ í•´ê²°ì— ê¸°ì—¬í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ì—°êµ¬ë“¤ì€ íŠ¹íˆ ìƒë¬¼ì •ë³´í•™ì˜ ë°œì „ì— ì¤‘ìš”í•œ ì—­í• ì„ í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ìµœê·¼ì—ëŠ” ë¹…ë°ì´í„° ìœµí•© ë¶„ì•¼ì—ì„œì˜ ì—°êµ¬ë¥¼ í†µí•´ ë‹¤ì–‘í•œ ê³ ì°¨ì› ë°ì´í„°ì˜ ë¶„ì„ ë° ì²˜ë¦¬ë¥¼ ìœ„í•œ ìƒˆë¡œìš´ ë°©ë²•ë¡  ê°œë°œì— ì§‘ì¤‘í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ì—°êµ¬ëŠ” ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤ì˜ ë°œì „ê³¼ ì‘ìš©ì— ì¤‘ìš”í•œ ê¸°ì—¬ë¥¼ í•˜ê³  ìˆìœ¼ë©°, íŠ¹íˆ ì˜ë£Œ ë° ìƒë¬¼ì •ë³´í•™ ë¶„ì•¼ì—ì„œì˜ í˜ì‹ ì ì¸ ì—°êµ¬ ê²°ê³¼ë¥¼ ë„ì¶œí•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ë…¸ë§¹ì„ êµìˆ˜ë‹˜ì€ í†µê³„í•™, ìƒë¬¼ì •ë³´í•™, ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ í™œë°œí•œ ì—°êµ¬ í™œë™ì„ í†µí•´ í•™ë¬¸ì  ë°œì „ì— ê¸°ì—¬í•˜ê³  ìˆìœ¼ë©°, íŠ¹íˆ ë°ì´í„°ì˜ ë³µì¡ì„±ì„ ë‹¤ë£¨ëŠ” ë° í•„ìš”í•œ ì´ë¡ ì  ë° ì‹¤ìš©ì  ì ‘ê·¼ ë°©ì‹ì„ ê°œë°œí•˜ëŠ” ë° ì¤‘ì ì„ ë‘ê³  ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# 1. í•œê¸€ ì§ˆë¬¸ ì…ë ¥\n",
    "question_ko = \"ë…¸ë§¹ì„ êµìˆ˜ë‹˜ì˜ ì—°êµ¬ ë™í–¥ ì•Œë ¤ì¤˜\"\n",
    "\n",
    "# 2. ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜\n",
    "question_type = classify_question_type(question_ko).strip()\n",
    "\n",
    "# 3. ì§ˆë¬¸ ì˜ì–´ë¡œ ë²ˆì—­ (Chroma DB ê²€ìƒ‰ìš©)\n",
    "question_en = translate_with_gpt(question_ko)\n",
    "\n",
    "# 4. Chroma DB ê²€ìƒ‰\n",
    "docs = db3.similarity_search(question_en, k=30)\n",
    "context_text = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "# 5. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜\n",
    "prompt_templates = {\n",
    "    \"ë…¼ë¬¸_ëª©ë¡\": PromptTemplate(\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "        template=\"\"\"\n",
    "You are provided with a collection of academic papers written by a professor. \n",
    "Based on the following user request, list the key papers along with:\n",
    "\n",
    "1. The title of each paper  \n",
    "2. The publication year (if available)  \n",
    "3. A few core keywords representing the main topic\n",
    "\n",
    "User question:\n",
    "{question}\n",
    "\n",
    "Paper content:\n",
    "{context}\n",
    "\n",
    "ğŸ“Œ Please write your response in Korean using a respectful and organized tone.\n",
    "\n",
    "ë…¼ë¬¸ ëª©ë¡ ìš”ì•½ (in Korean):\"\"\"\n",
    "    ),\n",
    "    \"ë…¼ë¬¸_ìš”ì•½\": PromptTemplate(\n",
    "        input_variables=[\"context\"],\n",
    "        template=\"\"\"\n",
    "You are a research summarization assistant. Based on the following academic paper, provide a clear and concise summary including the following elements:\n",
    "\n",
    "1. Research subject (what or who is being studied)  \n",
    "2. Research method (how it was studied)  \n",
    "3. Research findings (what was discovered)  \n",
    "4. Suggestions or implications (recommendations or conclusions)\n",
    "\n",
    "Paper content:\n",
    "{context}\n",
    "\n",
    "ğŸ“Œ Please write your summary in Korean, using a polite and professional tone.\n",
    "\n",
    "ë…¼ë¬¸ ìš”ì•½ (in Korean):\"\"\"\n",
    "    ),\n",
    "    \"ì—°êµ¬_íë¦„\": PromptTemplate(\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "        template=\"\"\"\n",
    "You are an academic assistant. Given a collection of research papers written by a single professor, analyze how the research topics or areas of interest have evolved over time. \n",
    "Identify key shifts, trends, or patterns chronologically based on the publication content.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Now, summarize the chronological progression of the professorâ€™s research focus. \n",
    "ğŸ“Œ Please write your answer in Korean using a clear and respectful tone.\n",
    "\n",
    "ì—°êµ¬ íë¦„ ìš”ì•½ (í•œêµ­ì–´ë¡œ):\"\"\"\n",
    "    )\n",
    "}\n",
    "\n",
    "# 6. í”„ë¡¬í”„íŠ¸ ì„ íƒ + LLM êµ¬ì„±\n",
    "prompt = prompt_templates.get(question_type, prompt_templates[\"ë…¼ë¬¸_ìš”ì•½\"])\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "chain = prompt | llm  # ìµœì‹  LangChain ë°©ì‹\n",
    "\n",
    "# 7. ì‹¤í–‰\n",
    "inputs = {\"context\": context_text}\n",
    "if \"question\" in prompt.input_variables:\n",
    "    inputs[\"question\"] = question_ko\n",
    "\n",
    "result = chain.invoke(inputs)\n",
    "\n",
    "# 8. ê²°ê³¼ ì¶œë ¥\n",
    "print(f\"[{question_type.upper()}]\")\n",
    "print(result.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
