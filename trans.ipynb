{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d9e976",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from openai import OpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import Document\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# ğŸ”‘ í™˜ê²½ ì„¤ì •\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"OPENAI_API_KEY\"  # â† ì‹¤ì œ í‚¤ë¡œ êµì²´\n",
    "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "embedding = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee5d3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "db3 = Chroma(\n",
    "    persist_directory=\"./chroma_db\",\n",
    "    embedding_function=embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67238f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "125131bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… í•œ-ì˜ êµìˆ˜ ì´ë¦„ ë§¤í•‘\n",
    "professor_name_map = {\n",
    "    \"ë…¸ë§¹ì„\": \"Maengseok Noh\",\n",
    "    \"ë¬¸í˜•ë¹ˆ\": \"HyungBin Moon\",\n",
    "    \"í•˜ì§€í™˜\": \"Jihwan Ha\",\n",
    "    \"ì§€ì¤€í™”\": \"Junhwa Chi\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56a87074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… ë²ˆì—­\n",
    "def translate_with_gpt(text, source_lang=\"ko\", target_lang=\"en\") -> str:\n",
    "    prompt = f\"Translate this from {source_lang} to {target_lang}:\\n\\n{text}\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.3\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1e20ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜\n",
    "def classify_question_type(question_ko: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "ë‹¤ìŒ ì§ˆë¬¸ì˜ ìœ í˜•ì„ ì•„ë˜ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•´ ì£¼ì„¸ìš”:\n",
    "- ë…¼ë¬¸_ëª©ë¡\n",
    "- ë…¼ë¬¸_ìš”ì•½\n",
    "- ì—°êµ¬_íë¦„\n",
    "\n",
    "ì§ˆë¬¸: {question_ko}\n",
    "ì§ˆë¬¸ ìœ í˜•:\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt.strip()}],\n",
    "        temperature=0\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f2a4df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The list of Professor Moon Hyung-bin's papers is\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate_with_gpt(\"ë¬¸í˜•ë¹ˆ êµìˆ˜ë‹˜ì˜ ë…¼ë¬¸ ëª©ë¡ì€\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed3fe5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… êµìˆ˜ëª… ì¶”ì¶œ\n",
    "def extract_professor_name(question: str) -> str | None:\n",
    "    match = re.search(r\"([ê°€-í£]{2,4})\\s*êµìˆ˜\", question)\n",
    "    return match.group(1) if match else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d537120",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_page_summary(doc: Document) -> str:\n",
    "    # ì „ì²´ page_contentì—ì„œ ì²« ë¬¸ë‹¨ ë˜ëŠ” ì•ë¶€ë¶„ë§Œ ìš”ì•½ìš©ìœ¼ë¡œ ìë¦„\n",
    "    content = doc.page_content.strip().split(\"\\n\")[:2]  # ì²« ì¤„ë§Œ\n",
    "    return f\"ğŸ“„ {content}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9812b9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… ë¬¸ì„œ í¬ë§· êµ¬ì„± (êµìˆ˜ëª…ë§Œ ì¡´ì¬í•˜ëŠ” ë©”íƒ€ë°ì´í„° êµ¬ì¡° ëŒ€ì‘)\n",
    "def format_doc_with_metadata(doc: Document) -> str:\n",
    "    professor = doc.metadata.get(\"professor\", \"êµìˆ˜ ì •ë³´ ì—†ìŒ\")\n",
    "    content = doc.page_content[:500] + \"...\" if len(doc.page_content) > 500 else doc.page_content\n",
    "    return f\"\"\"ğŸ§‘â€ğŸ« êµìˆ˜: {professor}\n",
    "ğŸ“„ ë‚´ìš© ìš”ì•½:\n",
    "{content}\n",
    "\"\"\"\n",
    "\n",
    "# âœ… í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "prompt_templates = {\n",
    "    \"ë…¼ë¬¸_ëª©ë¡\": PromptTemplate(\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "        template=\"\"\"\n",
    "You are provided with a collection of academic papers written by a professor. \n",
    "Based on the following user request, list the key papers along with:\n",
    "\n",
    "1. The title of each paper (ğŸ“Œ Please keep the title in English)  \n",
    "2. The publication year (if available)  \n",
    "3. A few core keywords representing the main topic (in Korean)  \n",
    "4. The author(s) of each paper (in Korean)\n",
    "\n",
    "User question:\n",
    "{question}\n",
    "\n",
    "Paper content:\n",
    "{context}\n",
    "\n",
    "ğŸ“Œ Please write your response in Korean using a respectful and organized tone, **but keep the paper titles in English**.\n",
    "\n",
    "ë…¼ë¬¸ ëª©ë¡ ìš”ì•½ (in Korean):\"\"\"\n",
    "    ),\n",
    "    \"ë…¼ë¬¸_ìš”ì•½\": PromptTemplate(\n",
    "        input_variables=[\"context\"],\n",
    "        template=\"\"\"\n",
    "You are a research summarization assistant. Based on the following academic paper, provide a clear and concise summary including the following elements:\n",
    "\n",
    "1. Research subject (what or who is being studied)  \n",
    "2. Research method (how it was studied)  \n",
    "3. Research findings (what was discovered)  \n",
    "4. Suggestions or implications (recommendations or conclusions)\n",
    "\n",
    "Paper content:\n",
    "{context}\n",
    "\n",
    "ğŸ“Œ Please write your summary in Korean, using a polite and professional tone.\n",
    "\n",
    "ë…¼ë¬¸ ìš”ì•½ (in Korean):\"\"\"\n",
    "    ),\n",
    "    \"ì—°êµ¬_íë¦„\": PromptTemplate(\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "        template=\"\"\"\n",
    "You are an academic assistant. Given a collection of research papers written by a single professor, analyze how the research topics or areas of interest have evolved over time. \n",
    "Identify key shifts, trends, or patterns chronologically based on the publication content.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Now, summarize the chronological progression of the professorâ€™s research focus. \n",
    "ğŸ“Œ Please write your answer in Korean using a clear and respectful tone.\n",
    "\n",
    "ì—°êµ¬ íë¦„ ìš”ì•½ (í•œêµ­ì–´ë¡œ):\"\"\"\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "df673480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_question(question_ko: str):\n",
    "    # 1. ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜\n",
    "    question_type = classify_question_type(question_ko)\n",
    "\n",
    "    # 2. êµìˆ˜ ì´ë¦„ ì¶”ì¶œ\n",
    "    target_author_ko = extract_professor_name(question_ko)\n",
    "    target_author_en = professor_name_map.get(target_author_ko) if target_author_ko else None\n",
    "\n",
    "    if question_type in [\"ë…¼ë¬¸_ëª©ë¡\", \"ì—°êµ¬_íë¦„\"] and not target_author_en:\n",
    "        raise ValueError(\"ì§ˆë¬¸ì—ì„œ ìœ íš¨í•œ êµìˆ˜ ì´ë¦„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    # 3. ì§ˆë¬¸ ë²ˆì—­\n",
    "    question_en = translate_with_gpt(question_ko)\n",
    "\n",
    "    # 4. ê²€ìƒ‰ (professor ê¸°ì¤€ ìˆ˜ë™ í•„í„°ë§)\n",
    "    collection = db3._collection.get(include=[\"metadatas\", \"documents\"])\n",
    "\n",
    "    # metadatasì™€ documentsë¥¼ ë¬¶ì–´ì„œ Document ê°ì²´ë¡œ ì¬êµ¬ì„±\n",
    "    docs = [\n",
    "        Document(page_content=page, metadata=meta)\n",
    "        for page, meta in zip(collection[\"documents\"], collection[\"metadatas\"])\n",
    "        if meta.get(\"professor\") == target_author_en\n",
    "    ]\n",
    "\n",
    "    # 5. ì²« í˜ì´ì§€ ê¸°ë°˜ ìš”ì•½ìš© context êµ¬ì„±\n",
    "    context_text = \"\\n\\n---\\n\\n\".join(get_first_page_summary(doc) for doc in docs)\n",
    "\n",
    "    # 6. í”„ë¡¬í”„íŠ¸ ì„¤ì •\n",
    "    if question_type == \"ë…¼ë¬¸_ëª©ë¡\":\n",
    "        context_text = \"\\n\\n---\\n\\n\".join(get_first_page_summary(doc) for doc in docs)\n",
    "        prompt = prompt_templates[\"ë…¼ë¬¸_ëª©ë¡\"]\n",
    "\n",
    "    elif question_type == \"ì—°êµ¬_íë¦„\":\n",
    "        context_text = \"\\n\\n---\\n\\n\".join(get_first_page_summary(doc) for doc in docs)\n",
    "        prompt = prompt_templates[\"ì—°êµ¬_íë¦„\"]\n",
    "\n",
    "    else:  # ë…¼ë¬¸_ìš”ì•½\n",
    "        context_text = \"\\n\\n---\\n\\n\".join(doc.page_content for doc in docs)\n",
    "        prompt = prompt_templates[\"ë…¼ë¬¸_ìš”ì•½\"]\n",
    "\n",
    "\n",
    "    # 7. ì‹¤í–‰\n",
    "    chain = prompt | ChatOpenAI(model=\"gpt-4o\")\n",
    "    inputs = {\"context\": context_text}\n",
    "    if \"question\" in prompt.input_variables:\n",
    "        inputs[\"question\"] = question_ko\n",
    "\n",
    "    result = chain.invoke(inputs)\n",
    "\n",
    "    print(f\"[{question_type.upper()}]\")\n",
    "    print(result.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c9437f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ë…¼ë¬¸_ëª©ë¡]\n",
      "ë…¸ë§¹ì„ êµìˆ˜ë‹˜ì˜ ë…¼ë¬¸ì„ ë‹¤ìŒê³¼ ê°™ì´ ì •ë¦¬í•˜ì˜€ìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. **Title**: \"STATISTICS IN MEDICINE\"\n",
      "   - **Publication Year**: 2006\n",
      "   - **Core Keywords**: ì˜ë£Œ í†µê³„, frailty ëª¨ë¸, ì´ì§ˆì„±\n",
      "   - **Authors**: ë…¸ë§¹ì„, í•˜ì¸ë“, ì´ì˜ì¡°\n",
      "\n",
      "2. **Title**: \"Robust estimation of dropout models using hierarchical likelihood\"\n",
      "   - **Publication Year**: 2011\n",
      "   - **Core Keywords**: ê²°ì¸¡ ë°ì´í„°, robust estimation, ê³„ì¸µì  ìš°ë„\n",
      "   - **Authors**: ë…¸ë§¹ì„, ì´ì˜ì¡°, ì¼„ì›Œë“œ ë§ˆì´í´ G.\n",
      "\n",
      "3. **Title**: \"Multicomponent Variance Estimation for Binary Traits\"\n",
      "   - **Publication Year**: 2006\n",
      "   - **Core Keywords**: ì´ë¶„í˜• í˜•ì§ˆ, ë¶„ì‚° ì¶”ì •, ìœ ì „ í†µê³„\n",
      "   - **Authors**: ë…¸ë§¹ì„, ì´ì˜ì¡°\n",
      "\n",
      "4. **Title**: \"Double hierarchical generalized linear models (with discussion)\"\n",
      "   - **Publication Year**: 2006\n",
      "   - **Core Keywords**: ì´ì¤‘ ê³„ì¸µì  ì¼ë°˜í™” ì„ í˜• ëª¨ë¸, í†µê³„ ëª¨í˜•, ë¶„ì‚° êµ¬ì„± ìš”ì†Œ\n",
      "   - **Authors**: ì´ì˜ì¡°, ë„¬ë” J.A.\n",
      "\n",
      "5. **Title**: \"Journal of Multivariate Analysis\"\n",
      "   - **Publication Year**: 2007\n",
      "   - **Core Keywords**: ë‹¤ë³€ëŸ‰ ë¶„ì„, í†µê³„ì  íš¨ìœ¨ì„±, REML ì ˆì°¨\n",
      "   - **Authors**: ë…¸ë§¹ì„, ì´ì˜ì¡°\n",
      "\n",
      "ì´ ëª©ë¡ì€ ë…¸ë§¹ì„ êµìˆ˜ë‹˜ì˜ ëŒ€í‘œì ì¸ ë…¼ë¬¸ë“¤ë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë©°, ê° ë…¼ë¬¸ì€ íŠ¹ì • í†µê³„ì  ë°©ë²•ë¡ ì´ë‚˜ ë°ì´í„° ë¶„ì„ ê¸°ìˆ ì„ ì‹¬ë„ ìˆê²Œ ë‹¤ë£¨ê³  ìˆìŠµë‹ˆë‹¤. ì¶”ê°€ì ì¸ ë…¼ë¬¸ë„ ìˆìœ¼ë‹ˆ, íŠ¹ì • ì£¼ì œë‚˜ ì—°êµ¬ì— ëŒ€í•œ ë” ìƒì„¸í•œ ì •ë³´ê°€ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# âœ… ì‹¤í–‰ ì˜ˆì‹œ\n",
    "question_ko = \"ë…¸ë§¹ì„ êµìˆ˜ë‹˜ì˜ ë…¼ë¬¸ ì •ë¦¬í•´ì¤˜\"\n",
    "process_question(question_ko)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
